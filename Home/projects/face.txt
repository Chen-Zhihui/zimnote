Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2018-08-16T19:44:36+08:00

====== face ======
Created 星期四 16 八月 2018

目标：技术成熟，全链条

====== 数据字典 ======

[ ] TDO: 数据字典，以下内容要标准化，用excel表格管理 
	* 仿照fastai做一份数据字典
	* 命令行参数，标准化的参数及处理函数应该写在基础开发库中
	* 算法参数
	* 界面显示值
	* 接口参数规范 
		* 算法，界面之间需要传递参数，一律传字符串，
		[>] ~~界面端，需要利用一个属性编辑框架，为每组参数找到合适的界面，或建立数据手册，按变量名字找到适当类型的控件，总之这一块比较麻烦QtMvvc~~
		* 暂时方案，用一个文本编辑器编辑json形式的参数，代替复杂的控件

====== 命令行规范，代码和测试框架 ======

[*] EXP: 命令行程序框架 <2018-08-23
	[*] 日志文件，把日志文件输出到一个临时文件夹中
	[*] 在调试界面中增加命令行参数，写一下VS2017的使用手册
	[*] 在命令行输出参数，全部配置到软件内部的配置中去，要配置到一个单独的根下面去
	[*] 输出配置信息时，输出成json形式
	[*] 以Poco为基础开发库，以json文件做配置文件，~~以ceral做序列化~~，写程序框架 
		[*] 软件内建一个json的模板，封装在一个虚函数中
		[*] 增一个命令行参数，将参数模板输出到json文件中，在启动参数中要设置下当前工作路径
		[*] 日志也输出到当前工作路径中
	[*] 命令行参数标准化
		[*] -help, 输出默认配置参数
		[*] config
	[*] 配置文件用层叠式
		[*] 程序编码中用jsonpp写配置，序列化后交给Poco::XmlConfigure，优先级最低
		[*] 启动后在当前目录或默认目录找配置文件，优先级中等
		[*] 命令行中指定参数config=filepath, 优先级最高
	[*] 划分功能模块，整理cmake安装脚本

====== 算法框架 ======
[ ] TDO: 算法库框架「沿着一个思路复盘，解决遇到的通用问题」
	* 注意问题
		* 首先opencv算法了解概念
		* 优先caffe转成caffe2模型，做C++接口
	* 重点参考
		* https://github.com/tpys/face-everthing
	* 算法测试框架：用OpenCV实现如何算法 
		[*] 头像检测
			* mtcnn using caffe2, cmake
			* VL: RSA
		[*] 画检测框
		[*] 追踪，
		[*] **关键点检测**，
		[*] 画关键点
		[*] **头部位置估计**
		[*] 画方位框
		[*] 所有结果都直接画在视频中，截图放在一个文件夹中
		[*] 输出成json
		[*] 命令行工具
		[*] https://github.com/kurnianggoro/GSOC2017 FaceMark的参考
		[*] 更换一个更精准的识别算法，或是用多个识别算法做二次识别，用MTCNN做二次识别，消除假识别
		* 头像对齐
			* tform, cp2tform, python的实现https://github.com/clcarwin/sphereface_pytorch/blob/master/matlab_cp2tform.py 
			* ALG: cp2tform, control point to transform, 该函数由输入的两幅图像的对应点生成变换结构，有函数名可以简单的理解为:contrlol points(cp) to transform(tform)  
			* EXP: github + algname + language:C++ 
	* 头像预处理
		* 边缘随机化
	* 特征提取
		* 准备数据
			* 从现有的训练数据中提取照片
			* 对齐操作
			* 准备一组小量的数据，用于测试
			* 准备一组小量数据，但每个人都有一定数目的照片
		* 需要一个现成的模型
			* sphereface+caffe -> caffe2 
				* pytorch https://github.com/clcarwin/sphereface_pytorch  值得用新版的pytorch复现一次，这里已有完整的思路了 
				* EXP: insightface + Pytorch https://github.com/TreB1eN/InsightFace_Pytorch 调查清楚这个训练库用到的数据我现有模型用于复现 <2018-09-24 
		* 特征以适当的数据库保存
	* 检索框架
		* FALCNN，这是一个已知可用的算法，并且有相关参数
	* **要考虑下，如何才能简化接口，方便编程**
	* 运算速度
		* 换用深度学习框架，因为经过专门的优化，所以速度要快一些，如果能用本机的GPU就更好了
		* 只处理关键帧，目前可以不考虑，只考虑算法收集
	* 引入识别算法时要用深度学习框架
	* 阶段性结果
		* 用opencv完成检测，特征点识取，追踪算法
		* pyannote，包括聚类和识别算法
		* 使用深度学习框架，配全这些算法
		* 熟悉算法训练过程，调参
	* 收集比较算法（没有价值，只是把别人的算法用了一下，如果是在项目中比较应用是有价值的）
		* 目前由企业开源的算法 libfacedetection, 中科院
	* 接口定义
		* 以opencv为开发库，整理有关face的全部算法  
			* 可能需要自己编译opencv
		* 算法参数定义成结构体，json序列化
		* 算法接口用expected
		* 写成命令行工具，用opencv的读写接口
			* 测试数据
			* 把结果直接画到视频中或图片中，在没有GUI的情况下，进行结果展示
		* 模块划分
			* 输出输出参考openface
				* 支持视频，文件，序列，摄像头，目前支持这些内容是一个错误，这个优先级低
				* 需要boost
				* opencv中打开视频和打开摄像头的方法是什么
				* 打开摄像头之后如何做简单的显示，利用opencv的显示？
			* 标准参数检查
	* 测试数据和多种算法验证
		* 用中科院的测试数据验证头部角度
		* 用模拟数据验证头部角度
		* 用dlib中的算法与opencv中的算法交叉验证检测结果，去掉不对的检测结果，去除掉可能性低的
		* 学习openface中的检测算法
		* 学习annotation中的追踪和检测算法
	* 发展的逻辑：视频索引工具，目前还没有找到更好的应用场景
		* 功能要求，算法需求
			* 检测, opencv, mtcnn
			* 对齐：参考seetaface( not seetaface2)中的tform/Aligner/TransformationMakerNet
			* 追踪, opencv
			* 关键点提取, opencv
			* 头部位置估计, pnp
			* 聚类，追踪到的头像属于一个人，但一个人的头像可以出现在多个时段，需要合并
			* 识别
			* 标注：标注视频中出现的人物时间段
		* 接口定义
			* 参考seetaface, 
				* SeetaFace2中去掉了一些代码，这些代码可用于头像旋转
				* download https://pan.baidu.com/s/1HJj8PEnv3SOu6ZxVpAHPXg 
				[*] pytorch https://conda.anaconda.org/pytorch/linux-64/pytorch-0.4.1-py36_py35_py27__9.0.176_7.1.2_2.tar.bz2 <2018-09-21
			* face-everyting, https://github.com/nicehuster/face-everything
		* 性能要求
			* 快速
				* 只处理关键帧
				* 采用深度学习框架
			* 稳定
	* 视频处理程序
		* 做一个产品设计
			* 找一个线框图工具
		* 这个是带GUI的
			* 将做为标注工具使用，将来要连服务器
			* 算法在后台线程中运行，提示用户找到合适的图片，用户如否决，则继续找，或是认可，则停止找
			* 用户选好头像好，显示一个标注页面，提示用户输入头像的名称
			* 全部信息准备好后，提交到服务器中
			* 要做为EBox的一个模块使用，用户从资源库中选出素材，在EBox上完成头像注标，然后提交
			* 按这个需求说下去，也就是说要给一个文件路径，从视频中提取出头像出来
			* 模块划分
				* 识别模块做成一个独立的QML模块使用
				* EBox中选文件，并有标注及提交界面，可以做成与Space并列的模块
		* 有GUI显示效果，备选方案： 可选方案多了，也是一个痛苦的事情 
			* Qt的播放器框架
				* 把playface中的现有模块移出来，做成专门的开发库
			* MTL框架
			* livecv
				* 实现了CV与QML的交互，但这样一个框架能做什么呢？
				* 在写GUI程序时可以用上这个库，直接把CV的数据，显示到QML中
			* 自写一个分析图片的工具
				* 这是就有点大了，如果要做的话，也应该在mitk中完成
		* 利用上面的命令行程序框架和算法库框架，写处理视频的程序
		* 输出格式暂定为json

[[+playface]]


[[+detector]]
[[+tracker]]
[[+croper]]
[[+headpose]] 
[[+aligner]]
[[+swaper]]
[[+landmarker]]
[[+feature]]
[[+validator]]
[[+recognizer]]
[[+eigenface]]
[[+morphing]]
+average


[[+people]]

====== 演示界面 ======

[ ] KEY: 演示界面 <2018-02-01
		[ ] 如同微软演示界面的框架，不要做一个包含众多功能的GUI，没有用处，
			[ ] 一个GUI页面只演示一个主题 
			[ ] GUI框架，找一下以前写的框架，Qt+Poco+Async+RxCpp+RxQt
			[ ] 存储：
				[ ] 图片：文件夹存储
				[ ] 特征：SQLite数据库
					[ ] 需要一个ORM框架
		[ ] 优先做识别演示框架，这一次做一个百万量级的检索框架
			[ ] 建库
				[ ] 模型文件的存储
				[ ] 项目文件夹：原图片文件，模型文件，ID数据库
				[ ] 特征提取：批量特征提取
			[ ] 检索
		[ ] 视频处理框架，用播放器演示

====== 数据 ======
@dataset

===== dataset =====

===== data api =====
Insightface集中了多个数据集，并提供了百度网盘的下载，格式，mxnet
[x] ms1m-v2
[*] ms1m-v1
[x] vggface2
[*] casia-webface
[x] glint-all
[*] glint-asia

Insightface_pytorch，把insightface的数据格式，转换成普通的文件格式
